{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: pysparkNote: you may need to restart the kernel to use updated packages.\n",
      "Version: 3.4.0\n",
      "Summary: Apache Spark Python API\n",
      "Home-page: https://github.com/apache/spark/tree/master/python\n",
      "Author: Spark Developers\n",
      "Author-email: dev@spark.apache.org\n",
      "License: http://www.apache.org/licenses/LICENSE-2.0\n",
      "Location: c:\\users\\asus\\appdata\\local\\programs\\python\\python310\\lib\\site-packages\n",
      "Requires: py4j\n",
      "Required-by: \n",
      "\n"
     ]
    }
   ],
   "source": [
    "pip show pyspark\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.getOrCreate()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create SQL View with Json File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.json(\"db.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- employee: array (nullable = true)\n",
      " |    |-- element: struct (containsNull = true)\n",
      " |    |    |-- active: boolean (nullable = true)\n",
      " |    |    |-- email: string (nullable = true)\n",
      " |    |    |-- id: long (nullable = true)\n",
      " |    |    |-- name: string (nullable = true)\n",
      " |    |    |-- phone: string (nullable = true)\n",
      "\n",
      "+--------------------+\n",
      "|            employee|\n",
      "+--------------------+\n",
      "|[{true, aisyah112...|\n",
      "+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = spark.read.option(\"multiline\",\"true\").json(\"db.json\")\n",
    "df.printSchema()\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.createOrReplaceTempView(\"df\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|            employee|\n",
      "+--------------------+\n",
      "|[{true, aisyah112...|\n",
      "+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql (\"select * from df\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+\n",
      "|count(employee)|\n",
      "+---------------+\n",
      "|              1|\n",
      "+---------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"select count (employee) from df\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- SR.: string (nullable = true)\n",
      " |-- NAME: string (nullable = true)\n",
      " |-- GENDER: string (nullable = true)\n",
      " |-- AGE: string (nullable = true)\n",
      " |-- DATE : string (nullable = true)\n",
      " |-- COUNTRY: string (nullable = true)\n",
      "\n",
      "+---+--------+------+---+----------+-------------+\n",
      "|SR.|    NAME|GENDER|AGE|     DATE |      COUNTRY|\n",
      "+---+--------+------+---+----------+-------------+\n",
      "|  1|    Dett|  Male| 18|21/05/2015|Great Britain|\n",
      "|  2|   Nern |Female| 19|15/10/2017|       France|\n",
      "|  3| Kallsie|  Male| 20|16/08/2016|       France|\n",
      "|  4|   Siuau|Female| 21|21/05/2015|Great Britain|\n",
      "|  5|Shennice|  Male| 22|21/05/2016|       France|\n",
      "|  6|  Chasse|Female| 23|15/10/2018|       France|\n",
      "|  7|  Tommye|  Male| 24|16/08/2017|United States|\n",
      "|  8| Dorcast|Female| 25|21/05/2016|United States|\n",
      "|  9| Angelee|  Male| 26|21/05/2017|Great Britain|\n",
      "| 10| Willoom|Female| 27|15/10/2019|       France|\n",
      "| 11| Waeston|  Male| 28|16/08/2018|Great Britain|\n",
      "| 12|   Rosma|Female| 29|21/05/2017|       France|\n",
      "| 13|Felisaas|  Male| 30|21/05/2018|       France|\n",
      "| 14| Demetas|Female| 31|15/10/2020|Great Britain|\n",
      "| 15| Jeromyw|Female| 32|16/08/2019|       France|\n",
      "| 16|  Rashid|Female| 33|21/05/2018|       France|\n",
      "| 17|    Dett|Female| 34|21/05/2019|United States|\n",
      "| 18|   Nern |Female| 35|15/10/2021|United States|\n",
      "| 19| Kallsie|Female| 36|16/08/2020|Great Britain|\n",
      "| 20|   Siuau|Female| 37|21/05/2019|       France|\n",
      "+---+--------+------+---+----------+-------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df2 = spark.read.option(\"header\",\"true\").csv(\"Employee Dataset.csv\")\n",
    "df2.printSchema()\n",
    "df2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.createOrReplaceTempView(\"df2\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select Column on Spark SQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------+------+---+----------+-------------+\n",
      "|SR.|    NAME|GENDER|AGE|     DATE |      COUNTRY|\n",
      "+---+--------+------+---+----------+-------------+\n",
      "|  1|    Dett|  Male| 18|21/05/2015|Great Britain|\n",
      "|  2|   Nern |Female| 19|15/10/2017|       France|\n",
      "|  3| Kallsie|  Male| 20|16/08/2016|       France|\n",
      "|  4|   Siuau|Female| 21|21/05/2015|Great Britain|\n",
      "|  5|Shennice|  Male| 22|21/05/2016|       France|\n",
      "|  6|  Chasse|Female| 23|15/10/2018|       France|\n",
      "|  7|  Tommye|  Male| 24|16/08/2017|United States|\n",
      "|  8| Dorcast|Female| 25|21/05/2016|United States|\n",
      "|  9| Angelee|  Male| 26|21/05/2017|Great Britain|\n",
      "| 10| Willoom|Female| 27|15/10/2019|       France|\n",
      "| 11| Waeston|  Male| 28|16/08/2018|Great Britain|\n",
      "| 12|   Rosma|Female| 29|21/05/2017|       France|\n",
      "| 13|Felisaas|  Male| 30|21/05/2018|       France|\n",
      "| 14| Demetas|Female| 31|15/10/2020|Great Britain|\n",
      "| 15| Jeromyw|Female| 32|16/08/2019|       France|\n",
      "| 16|  Rashid|Female| 33|21/05/2018|       France|\n",
      "| 17|    Dett|Female| 34|21/05/2019|United States|\n",
      "| 18|   Nern |Female| 35|15/10/2021|United States|\n",
      "| 19| Kallsie|Female| 36|16/08/2020|Great Britain|\n",
      "| 20|   Siuau|Female| 37|21/05/2019|       France|\n",
      "+---+--------+------+---+----------+-------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"select * from df2\").show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Count Syntax on Spark SQl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+\n",
      "|count(Name)|\n",
      "+-----------+\n",
      "|       5257|\n",
      "+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"select count(Name) from df2\").show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Where Clause on Spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------+-------------+\n",
      "|    Name|Gender|      Country|\n",
      "+--------+------+-------------+\n",
      "|    Dett|  Male|Great Britain|\n",
      "|   Nern |Female|       France|\n",
      "| Kallsie|  Male|       France|\n",
      "|   Siuau|Female|Great Britain|\n",
      "|Shennice|  Male|       France|\n",
      "|  Chasse|Female|       France|\n",
      "|  Tommye|  Male|United States|\n",
      "| Dorcast|Female|United States|\n",
      "| Angelee|  Male|Great Britain|\n",
      "| Willoom|Female|       France|\n",
      "| Waeston|  Male|Great Britain|\n",
      "|   Rosma|Female|       France|\n",
      "|Felisaas|  Male|       France|\n",
      "| Demetas|Female|Great Britain|\n",
      "|    Dett|  Male|Great Britain|\n",
      "|   Nern |Female|       France|\n",
      "| Kallsie|  Male|       France|\n",
      "|   Siuau|Female|Great Britain|\n",
      "|Shennice|  Male|       France|\n",
      "|  Chasse|Female|       France|\n",
      "+--------+------+-------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"select Name, Gender, Country from df2 where Age<=31\").show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filter Rows on Spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------+---+-------+\n",
      "|    Name|Gender|Age|Country|\n",
      "+--------+------+---+-------+\n",
      "|   Nern |Female| 19| France|\n",
      "| Kallsie|  Male| 20| France|\n",
      "|Shennice|  Male| 22| France|\n",
      "|  Chasse|Female| 23| France|\n",
      "| Willoom|Female| 27| France|\n",
      "|   Rosma|Female| 29| France|\n",
      "|Felisaas|  Male| 30| France|\n",
      "| Jeromyw|Female| 32| France|\n",
      "|  Rashid|Female| 33| France|\n",
      "|   Siuau|Female| 37| France|\n",
      "+--------+------+---+-------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df2.select(\"Name\",\"Gender\",\"Age\",\"Country\").where(\"Country == 'France'\").show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------+---+\n",
      "|    Name|Gender|Age|\n",
      "+--------+------+---+\n",
      "|    Dett|  Male| 18|\n",
      "|   Nern |Female| 19|\n",
      "| Kallsie|  Male| 20|\n",
      "|   Siuau|Female| 21|\n",
      "|Shennice|  Male| 22|\n",
      "|  Chasse|Female| 23|\n",
      "|  Tommye|  Male| 24|\n",
      "| Dorcast|Female| 25|\n",
      "| Angelee|  Male| 26|\n",
      "+--------+------+---+\n",
      "only showing top 9 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df2.select(\"Name\",\"Gender\",\"Age\").show(9)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sorting on Spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+---+-------------+\n",
      "|Name|Age|      Country|\n",
      "+----+---+-------------+\n",
      "|Dett| 18|Great Britain|\n",
      "|Dett| 18|Great Britain|\n",
      "|Dett| 18|Great Britain|\n",
      "|Dett| 18|Great Britain|\n",
      "|Dett| 18|Great Britain|\n",
      "|Dett| 18|Great Britain|\n",
      "|Dett| 18|Great Britain|\n",
      "|Dett| 18|Great Britain|\n",
      "|Dett| 18|Great Britain|\n",
      "|Dett| 18|Great Britain|\n",
      "+----+---+-------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df2.select(\"Name\",\"Age\",\"Country\",).where(\"Country in ('France','Great Britain')\").orderBy(\"Age\").show(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[SR.: string, NAME: string, GENDER: string, AGE: string, DATE : string, COUNTRY: string]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"select * from df2\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
